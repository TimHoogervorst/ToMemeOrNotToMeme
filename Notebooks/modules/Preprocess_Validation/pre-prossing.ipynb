{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile preprocess.py\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "class PreProcess():\n",
    "    def __init__(self, transform) -> None:\n",
    "       self.transform = transform\n",
    "       pass \n",
    "        \n",
    "    def process_image(self, image_path):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        return image, self.transform(image)\n",
    "\n",
    "    def pre_prosses_image(self, image_path) -> None:\n",
    "        original, prossessed_image = self.process_image(image_path)\n",
    "        prossessed_image.save(image_path)\n",
    "\n",
    "    def pre_prosses_data_set(self, folder_path) -> None:\n",
    "        images = glob.glob(f\"{folder_path}/*\")\n",
    "        for image in tqdm(images):\n",
    "            original, prossessed_image = self.preprocess_image(image, self.transform)\n",
    "            prossessed_image.save(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Pre-prosser for test set\n",
    "transform_full = transforms.Compose([\n",
    "    transforms.Resize((256,256)), \n",
    "    transforms.ToTensor()\n",
    "])\n",
    "PreProssor = PreProcess(transform_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6471, 0.6431, 0.6314,  ..., 0.0431, 0.0314, 0.0353],\n",
       "         [0.6039, 0.6000, 0.5765,  ..., 0.0588, 0.0588, 0.0588],\n",
       "         [0.5490, 0.5725, 0.5647,  ..., 0.0745, 0.0706, 0.0667],\n",
       "         ...,\n",
       "         [0.6157, 0.6196, 0.6275,  ..., 0.8627, 0.8627, 0.8667],\n",
       "         [0.6157, 0.6471, 0.7961,  ..., 0.8667, 0.8706, 0.8745],\n",
       "         [0.6471, 0.8353, 0.9725,  ..., 0.8824, 0.8784, 0.8824]],\n",
       "\n",
       "        [[0.5020, 0.4941, 0.5922,  ..., 0.0627, 0.0549, 0.0588],\n",
       "         [0.5451, 0.5412, 0.6078,  ..., 0.0824, 0.0824, 0.0824],\n",
       "         [0.7020, 0.6980, 0.6863,  ..., 0.0980, 0.0941, 0.0902],\n",
       "         ...,\n",
       "         [0.4784, 0.4824, 0.4863,  ..., 0.7569, 0.7569, 0.7608],\n",
       "         [0.4784, 0.5176, 0.6706,  ..., 0.7608, 0.7686, 0.7725],\n",
       "         [0.5020, 0.7137, 0.8549,  ..., 0.7765, 0.7765, 0.7804]],\n",
       "\n",
       "        [[0.5686, 0.6039, 0.7725,  ..., 0.1412, 0.1216, 0.1137],\n",
       "         [0.6824, 0.6980, 0.7961,  ..., 0.1490, 0.1451, 0.1451],\n",
       "         [0.9216, 0.9294, 0.9373,  ..., 0.1490, 0.1529, 0.1529],\n",
       "         ...,\n",
       "         [0.3490, 0.3412, 0.3373,  ..., 0.6471, 0.6431, 0.6431],\n",
       "         [0.3412, 0.3608, 0.4941,  ..., 0.6471, 0.6471, 0.6431],\n",
       "         [0.3647, 0.5529, 0.6627,  ..., 0.6549, 0.6471, 0.6471]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image = \"../DataBaseV2/Fun/IMG_8249.jpg\"\n",
    "original_image, image_tensor = PreProssor.process_image(test_image)\n",
    "image_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
