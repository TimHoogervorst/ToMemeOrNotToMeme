Name,kappa,recall,f1,precision,epochs,Parameters
MemeClassConv2d-HVN,0.1875,0.25,0.3809523809523809,0.8,30,"[['conv1.weight', torch.Size([6, 3, 5, 5])], ['conv1.bias', torch.Size([6])], ['conv2.weight', torch.Size([16, 6, 5, 5])], ['conv2.bias', torch.Size([16])], ['conv3.weight', torch.Size([32, 16, 5, 5])], ['conv3.bias', torch.Size([32])], ['fc1.weight', torch.Size([120, 25088])], ['fc1.bias', torch.Size([120])], ['fc2.weight', torch.Size([84, 120])], ['fc2.bias', torch.Size([84])], ['out.weight', torch.Size([2, 84])], ['out.bias', torch.Size([2])]]"
MemeClassConv2d-HVN+Pre,0.59375,0.84375,0.8059701492537314,0.7714285714285715,30,"[['conv1.weight', torch.Size([6, 3, 5, 5])], ['conv1.bias', torch.Size([6])], ['conv2.weight', torch.Size([16, 6, 5, 5])], ['conv2.bias', torch.Size([16])], ['conv3.weight', torch.Size([32, 16, 5, 5])], ['conv3.bias', torch.Size([32])], ['fc1.weight', torch.Size([120, 25088])], ['fc1.bias', torch.Size([120])], ['fc2.weight', torch.Size([84, 120])], ['fc2.bias', torch.Size([84])], ['out.weight', torch.Size([2, 84])], ['out.bias', torch.Size([2])]]"
efficientnet_b0,0.9634146341463414,0.9647058823529412,0.9820359281437124,0.9647058823529412,10,"[['base_model.conv_stem.weight', torch.Size([32, 3, 3, 3])], ['base_model.bn1.weight', torch.Size([32])], ['base_model.bn1.bias', torch.Size([32])], ['base_model.blocks.0.0.conv_dw.weight', torch.Size([32, 1, 3, 3])], ['base_model.blocks.0.0.bn1.weight', torch.Size([32])], ['base_model.blocks.0.0.bn1.bias', torch.Size([32])], ['base_model.blocks.0.0.se.conv_reduce.weight', torch.Size([8, 32, 1, 1])], ['base_model.blocks.0.0.se.conv_reduce.bias', torch.Size([8])], ['base_model.blocks.0.0.se.conv_expand.weight', torch.Size([32, 8, 1, 1])], ['base_model.blocks.0.0.se.conv_expand.bias', torch.Size([32])], ['base_model.blocks.0.0.conv_pw.weight', torch.Size([16, 32, 1, 1])], ['base_model.blocks.0.0.bn2.weight', torch.Size([16])], ['base_model.blocks.0.0.bn2.bias', torch.Size([16])], ['base_model.blocks.1.0.conv_pw.weight', torch.Size([96, 16, 1, 1])], ['base_model.blocks.1.0.bn1.weight', torch.Size([96])], ['base_model.blocks.1.0.bn1.bias', torch.Size([96])], ['base_model.blocks.1.0.conv_dw.weight', torch.Size([96, 1, 3, 3])], ['base_model.blocks.1.0.bn2.weight', torch.Size([96])], ['base_model.blocks.1.0.bn2.bias', torch.Size([96])], ['base_model.blocks.1.0.se.conv_reduce.weight', torch.Size([4, 96, 1, 1])], ['base_model.blocks.1.0.se.conv_reduce.bias', torch.Size([4])], ['base_model.blocks.1.0.se.conv_expand.weight', torch.Size([96, 4, 1, 1])], ['base_model.blocks.1.0.se.conv_expand.bias', torch.Size([96])], ['base_model.blocks.1.0.conv_pwl.weight', torch.Size([24, 96, 1, 1])], ['base_model.blocks.1.0.bn3.weight', torch.Size([24])], ['base_model.blocks.1.0.bn3.bias', torch.Size([24])], ['base_model.blocks.1.1.conv_pw.weight', torch.Size([144, 24, 1, 1])], ['base_model.blocks.1.1.bn1.weight', torch.Size([144])], ['base_model.blocks.1.1.bn1.bias', torch.Size([144])], ['base_model.blocks.1.1.conv_dw.weight', torch.Size([144, 1, 3, 3])], ['base_model.blocks.1.1.bn2.weight', torch.Size([144])], ['base_model.blocks.1.1.bn2.bias', torch.Size([144])], ['base_model.blocks.1.1.se.conv_reduce.weight', torch.Size([6, 144, 1, 1])], ['base_model.blocks.1.1.se.conv_reduce.bias', torch.Size([6])], ['base_model.blocks.1.1.se.conv_expand.weight', torch.Size([144, 6, 1, 1])], ['base_model.blocks.1.1.se.conv_expand.bias', torch.Size([144])], ['base_model.blocks.1.1.conv_pwl.weight', torch.Size([24, 144, 1, 1])], ['base_model.blocks.1.1.bn3.weight', torch.Size([24])], ['base_model.blocks.1.1.bn3.bias', torch.Size([24])], ['base_model.blocks.2.0.conv_pw.weight', torch.Size([144, 24, 1, 1])], ['base_model.blocks.2.0.bn1.weight', torch.Size([144])], ['base_model.blocks.2.0.bn1.bias', torch.Size([144])], ['base_model.blocks.2.0.conv_dw.weight', torch.Size([144, 1, 5, 5])], ['base_model.blocks.2.0.bn2.weight', torch.Size([144])], ['base_model.blocks.2.0.bn2.bias', torch.Size([144])], ['base_model.blocks.2.0.se.conv_reduce.weight', torch.Size([6, 144, 1, 1])], ['base_model.blocks.2.0.se.conv_reduce.bias', torch.Size([6])], ['base_model.blocks.2.0.se.conv_expand.weight', torch.Size([144, 6, 1, 1])], ['base_model.blocks.2.0.se.conv_expand.bias', torch.Size([144])], ['base_model.blocks.2.0.conv_pwl.weight', torch.Size([40, 144, 1, 1])], ['base_model.blocks.2.0.bn3.weight', torch.Size([40])], ['base_model.blocks.2.0.bn3.bias', torch.Size([40])], ['base_model.blocks.2.1.conv_pw.weight', torch.Size([240, 40, 1, 1])], ['base_model.blocks.2.1.bn1.weight', torch.Size([240])], ['base_model.blocks.2.1.bn1.bias', torch.Size([240])], ['base_model.blocks.2.1.conv_dw.weight', torch.Size([240, 1, 5, 5])], ['base_model.blocks.2.1.bn2.weight', torch.Size([240])], ['base_model.blocks.2.1.bn2.bias', torch.Size([240])], ['base_model.blocks.2.1.se.conv_reduce.weight', torch.Size([10, 240, 1, 1])], ['base_model.blocks.2.1.se.conv_reduce.bias', torch.Size([10])], ['base_model.blocks.2.1.se.conv_expand.weight', torch.Size([240, 10, 1, 1])], ['base_model.blocks.2.1.se.conv_expand.bias', torch.Size([240])], ['base_model.blocks.2.1.conv_pwl.weight', torch.Size([40, 240, 1, 1])], ['base_model.blocks.2.1.bn3.weight', torch.Size([40])], ['base_model.blocks.2.1.bn3.bias', torch.Size([40])], ['base_model.blocks.3.0.conv_pw.weight', torch.Size([240, 40, 1, 1])], ['base_model.blocks.3.0.bn1.weight', torch.Size([240])], ['base_model.blocks.3.0.bn1.bias', torch.Size([240])], ['base_model.blocks.3.0.conv_dw.weight', torch.Size([240, 1, 3, 3])], ['base_model.blocks.3.0.bn2.weight', torch.Size([240])], ['base_model.blocks.3.0.bn2.bias', torch.Size([240])], ['base_model.blocks.3.0.se.conv_reduce.weight', torch.Size([10, 240, 1, 1])], ['base_model.blocks.3.0.se.conv_reduce.bias', torch.Size([10])], ['base_model.blocks.3.0.se.conv_expand.weight', torch.Size([240, 10, 1, 1])], ['base_model.blocks.3.0.se.conv_expand.bias', torch.Size([240])], ['base_model.blocks.3.0.conv_pwl.weight', torch.Size([80, 240, 1, 1])], ['base_model.blocks.3.0.bn3.weight', torch.Size([80])], ['base_model.blocks.3.0.bn3.bias', torch.Size([80])], ['base_model.blocks.3.1.conv_pw.weight', torch.Size([480, 80, 1, 1])], ['base_model.blocks.3.1.bn1.weight', torch.Size([480])], ['base_model.blocks.3.1.bn1.bias', torch.Size([480])], ['base_model.blocks.3.1.conv_dw.weight', torch.Size([480, 1, 3, 3])], ['base_model.blocks.3.1.bn2.weight', torch.Size([480])], ['base_model.blocks.3.1.bn2.bias', torch.Size([480])], ['base_model.blocks.3.1.se.conv_reduce.weight', torch.Size([20, 480, 1, 1])], ['base_model.blocks.3.1.se.conv_reduce.bias', torch.Size([20])], ['base_model.blocks.3.1.se.conv_expand.weight', torch.Size([480, 20, 1, 1])], ['base_model.blocks.3.1.se.conv_expand.bias', torch.Size([480])], ['base_model.blocks.3.1.conv_pwl.weight', torch.Size([80, 480, 1, 1])], ['base_model.blocks.3.1.bn3.weight', torch.Size([80])], ['base_model.blocks.3.1.bn3.bias', torch.Size([80])], ['base_model.blocks.3.2.conv_pw.weight', torch.Size([480, 80, 1, 1])], ['base_model.blocks.3.2.bn1.weight', torch.Size([480])], ['base_model.blocks.3.2.bn1.bias', torch.Size([480])], ['base_model.blocks.3.2.conv_dw.weight', torch.Size([480, 1, 3, 3])], ['base_model.blocks.3.2.bn2.weight', torch.Size([480])], ['base_model.blocks.3.2.bn2.bias', torch.Size([480])], ['base_model.blocks.3.2.se.conv_reduce.weight', torch.Size([20, 480, 1, 1])], ['base_model.blocks.3.2.se.conv_reduce.bias', torch.Size([20])], ['base_model.blocks.3.2.se.conv_expand.weight', torch.Size([480, 20, 1, 1])], ['base_model.blocks.3.2.se.conv_expand.bias', torch.Size([480])], ['base_model.blocks.3.2.conv_pwl.weight', torch.Size([80, 480, 1, 1])], ['base_model.blocks.3.2.bn3.weight', torch.Size([80])], ['base_model.blocks.3.2.bn3.bias', torch.Size([80])], ['base_model.blocks.4.0.conv_pw.weight', torch.Size([480, 80, 1, 1])], ['base_model.blocks.4.0.bn1.weight', torch.Size([480])], ['base_model.blocks.4.0.bn1.bias', torch.Size([480])], ['base_model.blocks.4.0.conv_dw.weight', torch.Size([480, 1, 5, 5])], ['base_model.blocks.4.0.bn2.weight', torch.Size([480])], ['base_model.blocks.4.0.bn2.bias', torch.Size([480])], ['base_model.blocks.4.0.se.conv_reduce.weight', torch.Size([20, 480, 1, 1])], ['base_model.blocks.4.0.se.conv_reduce.bias', torch.Size([20])], ['base_model.blocks.4.0.se.conv_expand.weight', torch.Size([480, 20, 1, 1])], ['base_model.blocks.4.0.se.conv_expand.bias', torch.Size([480])], ['base_model.blocks.4.0.conv_pwl.weight', torch.Size([112, 480, 1, 1])], ['base_model.blocks.4.0.bn3.weight', torch.Size([112])], ['base_model.blocks.4.0.bn3.bias', torch.Size([112])], ['base_model.blocks.4.1.conv_pw.weight', torch.Size([672, 112, 1, 1])], ['base_model.blocks.4.1.bn1.weight', torch.Size([672])], ['base_model.blocks.4.1.bn1.bias', torch.Size([672])], ['base_model.blocks.4.1.conv_dw.weight', torch.Size([672, 1, 5, 5])], ['base_model.blocks.4.1.bn2.weight', torch.Size([672])], ['base_model.blocks.4.1.bn2.bias', torch.Size([672])], ['base_model.blocks.4.1.se.conv_reduce.weight', torch.Size([28, 672, 1, 1])], ['base_model.blocks.4.1.se.conv_reduce.bias', torch.Size([28])], ['base_model.blocks.4.1.se.conv_expand.weight', torch.Size([672, 28, 1, 1])], ['base_model.blocks.4.1.se.conv_expand.bias', torch.Size([672])], ['base_model.blocks.4.1.conv_pwl.weight', torch.Size([112, 672, 1, 1])], ['base_model.blocks.4.1.bn3.weight', torch.Size([112])], ['base_model.blocks.4.1.bn3.bias', torch.Size([112])], ['base_model.blocks.4.2.conv_pw.weight', torch.Size([672, 112, 1, 1])], ['base_model.blocks.4.2.bn1.weight', torch.Size([672])], ['base_model.blocks.4.2.bn1.bias', torch.Size([672])], ['base_model.blocks.4.2.conv_dw.weight', torch.Size([672, 1, 5, 5])], ['base_model.blocks.4.2.bn2.weight', torch.Size([672])], ['base_model.blocks.4.2.bn2.bias', torch.Size([672])], ['base_model.blocks.4.2.se.conv_reduce.weight', torch.Size([28, 672, 1, 1])], ['base_model.blocks.4.2.se.conv_reduce.bias', torch.Size([28])], ['base_model.blocks.4.2.se.conv_expand.weight', torch.Size([672, 28, 1, 1])], ['base_model.blocks.4.2.se.conv_expand.bias', torch.Size([672])], ['base_model.blocks.4.2.conv_pwl.weight', torch.Size([112, 672, 1, 1])], ['base_model.blocks.4.2.bn3.weight', torch.Size([112])], ['base_model.blocks.4.2.bn3.bias', torch.Size([112])], ['base_model.blocks.5.0.conv_pw.weight', torch.Size([672, 112, 1, 1])], ['base_model.blocks.5.0.bn1.weight', torch.Size([672])], ['base_model.blocks.5.0.bn1.bias', torch.Size([672])], ['base_model.blocks.5.0.conv_dw.weight', torch.Size([672, 1, 5, 5])], ['base_model.blocks.5.0.bn2.weight', torch.Size([672])], ['base_model.blocks.5.0.bn2.bias', torch.Size([672])], ['base_model.blocks.5.0.se.conv_reduce.weight', torch.Size([28, 672, 1, 1])], ['base_model.blocks.5.0.se.conv_reduce.bias', torch.Size([28])], ['base_model.blocks.5.0.se.conv_expand.weight', torch.Size([672, 28, 1, 1])], ['base_model.blocks.5.0.se.conv_expand.bias', torch.Size([672])], ['base_model.blocks.5.0.conv_pwl.weight', torch.Size([192, 672, 1, 1])], ['base_model.blocks.5.0.bn3.weight', torch.Size([192])], ['base_model.blocks.5.0.bn3.bias', torch.Size([192])], ['base_model.blocks.5.1.conv_pw.weight', torch.Size([1152, 192, 1, 1])], ['base_model.blocks.5.1.bn1.weight', torch.Size([1152])], ['base_model.blocks.5.1.bn1.bias', torch.Size([1152])], ['base_model.blocks.5.1.conv_dw.weight', torch.Size([1152, 1, 5, 5])], ['base_model.blocks.5.1.bn2.weight', torch.Size([1152])], ['base_model.blocks.5.1.bn2.bias', torch.Size([1152])], ['base_model.blocks.5.1.se.conv_reduce.weight', torch.Size([48, 1152, 1, 1])], ['base_model.blocks.5.1.se.conv_reduce.bias', torch.Size([48])], ['base_model.blocks.5.1.se.conv_expand.weight', torch.Size([1152, 48, 1, 1])], ['base_model.blocks.5.1.se.conv_expand.bias', torch.Size([1152])], ['base_model.blocks.5.1.conv_pwl.weight', torch.Size([192, 1152, 1, 1])], ['base_model.blocks.5.1.bn3.weight', torch.Size([192])], ['base_model.blocks.5.1.bn3.bias', torch.Size([192])], ['base_model.blocks.5.2.conv_pw.weight', torch.Size([1152, 192, 1, 1])], ['base_model.blocks.5.2.bn1.weight', torch.Size([1152])], ['base_model.blocks.5.2.bn1.bias', torch.Size([1152])], ['base_model.blocks.5.2.conv_dw.weight', torch.Size([1152, 1, 5, 5])], ['base_model.blocks.5.2.bn2.weight', torch.Size([1152])], ['base_model.blocks.5.2.bn2.bias', torch.Size([1152])], ['base_model.blocks.5.2.se.conv_reduce.weight', torch.Size([48, 1152, 1, 1])], ['base_model.blocks.5.2.se.conv_reduce.bias', torch.Size([48])], ['base_model.blocks.5.2.se.conv_expand.weight', torch.Size([1152, 48, 1, 1])], ['base_model.blocks.5.2.se.conv_expand.bias', torch.Size([1152])], ['base_model.blocks.5.2.conv_pwl.weight', torch.Size([192, 1152, 1, 1])], ['base_model.blocks.5.2.bn3.weight', torch.Size([192])], ['base_model.blocks.5.2.bn3.bias', torch.Size([192])], ['base_model.blocks.5.3.conv_pw.weight', torch.Size([1152, 192, 1, 1])], ['base_model.blocks.5.3.bn1.weight', torch.Size([1152])], ['base_model.blocks.5.3.bn1.bias', torch.Size([1152])], ['base_model.blocks.5.3.conv_dw.weight', torch.Size([1152, 1, 5, 5])], ['base_model.blocks.5.3.bn2.weight', torch.Size([1152])], ['base_model.blocks.5.3.bn2.bias', torch.Size([1152])], ['base_model.blocks.5.3.se.conv_reduce.weight', torch.Size([48, 1152, 1, 1])], ['base_model.blocks.5.3.se.conv_reduce.bias', torch.Size([48])], ['base_model.blocks.5.3.se.conv_expand.weight', torch.Size([1152, 48, 1, 1])], ['base_model.blocks.5.3.se.conv_expand.bias', torch.Size([1152])], ['base_model.blocks.5.3.conv_pwl.weight', torch.Size([192, 1152, 1, 1])], ['base_model.blocks.5.3.bn3.weight', torch.Size([192])], ['base_model.blocks.5.3.bn3.bias', torch.Size([192])], ['base_model.blocks.6.0.conv_pw.weight', torch.Size([1152, 192, 1, 1])], ['base_model.blocks.6.0.bn1.weight', torch.Size([1152])], ['base_model.blocks.6.0.bn1.bias', torch.Size([1152])], ['base_model.blocks.6.0.conv_dw.weight', torch.Size([1152, 1, 3, 3])], ['base_model.blocks.6.0.bn2.weight', torch.Size([1152])], ['base_model.blocks.6.0.bn2.bias', torch.Size([1152])], ['base_model.blocks.6.0.se.conv_reduce.weight', torch.Size([48, 1152, 1, 1])], ['base_model.blocks.6.0.se.conv_reduce.bias', torch.Size([48])], ['base_model.blocks.6.0.se.conv_expand.weight', torch.Size([1152, 48, 1, 1])], ['base_model.blocks.6.0.se.conv_expand.bias', torch.Size([1152])], ['base_model.blocks.6.0.conv_pwl.weight', torch.Size([320, 1152, 1, 1])], ['base_model.blocks.6.0.bn3.weight', torch.Size([320])], ['base_model.blocks.6.0.bn3.bias', torch.Size([320])], ['base_model.conv_head.weight', torch.Size([1280, 320, 1, 1])], ['base_model.bn2.weight', torch.Size([1280])], ['base_model.bn2.bias', torch.Size([1280])], ['base_model.classifier.weight', torch.Size([1000, 1280])], ['base_model.classifier.bias', torch.Size([1000])], ['classifier.weight', torch.Size([2, 1280])], ['classifier.bias', torch.Size([2])]]"
MemeClassifier,0.1585365853658537,0.5467625899280576,0.6877828054298643,0.5467625899280576,50,"[['fc1.weight', torch.Size([30, 196608])], ['fc1.bias', torch.Size([30])], ['fc2.weight', torch.Size([20, 30])], ['fc2.bias', torch.Size([20])], ['out.weight', torch.Size([2, 20])], ['out.bias', torch.Size([2])]]"
